{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the number of words spoken by male and female characters in calderon's comedias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_file = 'calderon-gender-prediction/all_characters.csv'\n",
    "character_df = pd.read_csv(character_file, usecols = ['id','genre','character_gender','character_id', 'scenes', 'utterances', 'tokens', 'words_spoken'])\n",
    "\n",
    "#only examine comedias files, not autos, loas, or zarzuelas\n",
    "comedias_df = character_df[(character_df['genre'] != 'auto sacramental') & \n",
    "                          (character_df['genre'] != 'loa') & \n",
    "                          (character_df['genre'] != 'zarzuela') & \n",
    "                          (character_df['genre'] != 'mojiganga')]\n",
    "\n",
    "#drop nan values\n",
    "\n",
    "comedias_df = comedias_df.dropna()\n",
    "comedias_df = comedias_df[comedias_df['words_spoken'] > 30]\n",
    "print(comedias_df.shape)\n",
    "print(comedias_df['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comedias_df['id'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart the number of words spoken by male and female characters\n",
    "for i in comedias_df['character_gender'].unique():\n",
    "    filtered_data = comedias_df[comedias_df['character_gender'] == i]\n",
    "    plt.hist(filtered_data['words_spoken'], label=i)\n",
    "    plt.title('Number of Words Spoken by Character Gender')\n",
    "    plt.xlabel('Number of Tokens Spoken')\n",
    "    plt.ylabel('Number of Characters')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the total number of words spoken by men and by women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the sum of the words spoken coulmn for each \n",
    "print(comedias_df.groupby('character_gender')['words_spoken'].sum())\n",
    "\n",
    "#print how many characters\n",
    "print(comedias_df.groupby('character_gender')['character_id'].nunique()) #but some names are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many characters in the corpus speak more than 30 words\n",
    "print(comedias_df[comedias_df['words_spoken'] > 30].shape)\n",
    "\n",
    "#count number of rows in the dataframe with male or female and > 30 words spoken\n",
    "print(comedias_df[comedias_df['words_spoken'] > 30]['character_gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the max, min, and mean of the number of words spoken by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in comedias_df['character_gender'].unique():\n",
    "    filtered_data = comedias_df[comedias_df['character_gender'] == i]\n",
    "    print(i)\n",
    "    print(filtered_data['words_spoken'].mean())\n",
    "    print(filtered_data['words_spoken'].median())\n",
    "    print(filtered_data['words_spoken'].std())\n",
    "    print(filtered_data['words_spoken'].min())\n",
    "    print(filtered_data['words_spoken'].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print proportion of rows where df['is_male'] == df['predictions']\n",
    "def proportion_correct(tokens_df, row_of_interest = 'predictions'):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    male_correct = 0\n",
    "    female_correct = 0\n",
    "    male_incorrect = 0\n",
    "    female_incorrect = 0\n",
    "\n",
    "    for index, row in tokens_df.iterrows():\n",
    "        if row['is_male'] == row[row_of_interest]:\n",
    "            correct += 1\n",
    "            if row['is_male'] == 1:\n",
    "                male_correct += 1\n",
    "            else:\n",
    "                female_correct += 1\n",
    "\n",
    "        else:\n",
    "            if row['is_male'] == 1:\n",
    "                male_incorrect += 1\n",
    "            \n",
    "            else:\n",
    "                female_incorrect += 1\n",
    "                \n",
    "\n",
    "        total += 1\n",
    "\n",
    "    if female_correct!=0 and male_correct!=0: #(male_correct + male_incorrect) != 0 and (female_correct + female_incorrect) != 0 and (male_correct + female_incorrect) !=0 and (female_correct + male_incorrect) !=0 and \n",
    "        m_precision = male_correct/(male_correct + female_incorrect)\n",
    "        m_recall = male_correct / (male_correct + male_incorrect)\n",
    "        m_f1 = 2 * (m_precision * m_recall) / (m_precision + m_recall)\n",
    "        print('Male F1: ',m_f1)\n",
    "\n",
    "        f_precision = female_correct / (female_correct + male_incorrect)\n",
    "        f_recall = female_correct / (female_correct + female_incorrect)\n",
    "        f_f1 = 2 * (f_precision * f_recall) / (f_precision + f_recall)\n",
    "        print('Female F1: ',f_f1)\n",
    "\n",
    "        average_precision = (m_precision + f_precision) / 2\n",
    "        average_recall = (m_recall + f_recall) / 2\n",
    "        average_f1 = (m_f1 + f_f1) / 2\n",
    "        print('Average Precision: ', average_precision)\n",
    "        print('Average Recall: ', average_recall)\n",
    "        print('Average F1: ', average_f1)\n",
    "    else:\n",
    "        print('Model made no correct predicitons for one class')\n",
    "        average_precision = 0\n",
    "        average_recall = 0\n",
    "        average_f1 = 0\n",
    "    return average_precision, average_recall, average_f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_numbers(input_string):\n",
    "    numbers = input_string.strip('[]').split()\n",
    "    numbers = [float(num) for num in numbers]\n",
    "    return numbers\n",
    "\n",
    "def geometric_mean_probability(df):\n",
    "    result_list = []\n",
    "\n",
    "    for (character_id, play_id), group in df.groupby(['character_id', 'id']):\n",
    "        # Extract the first and second numbers after '[' and ']'\n",
    "        probabilities = group['probabilities'].apply(lambda x: convert_string_to_numbers(x)[0])  # First number\n",
    "        second_probabilities = group['probabilities'].apply(lambda x: convert_string_to_numbers(x)[1])  # Second number\n",
    "\n",
    "\n",
    "        # Use the mean of the second probabilities for is_male == 1\n",
    "        if group['is_male'].iloc[0] == 1:\n",
    "            probabilities = second_probabilities\n",
    "\n",
    "        geometric_mean_prob = probabilities.prod() ** (1 / len(probabilities))\n",
    "        mean_actual = group['is_male'].mean()\n",
    "\n",
    "        # Round the mean prediction to either 0 or 1\n",
    "        mean_predict = round(geometric_mean_prob)\n",
    "\n",
    "        #column_name = group[column_name].iloc[0]\n",
    "\n",
    "        result_list.append({\n",
    "            'id': play_id,\n",
    "            'character_id': character_id,\n",
    "            'geometric_mean_probability': geometric_mean_prob,\n",
    "            'is_male': mean_actual,\n",
    "            'geo_predictions': mean_predict,\n",
    "            'average_prediction' : group['predictions'].mean()\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall, and F1-score for each level of text input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Level\n",
    "All lines a character speaks in a play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.read_csv('/projekte/tcl/users/keithan/projectcalderon/wp1-semantic-analysis/gender-predict-pkg/results/tokens_bert-base-spanish-wwm-cased_1e-05_24_5.csv')\n",
    "print(\"Character Level Predictions\")\n",
    "proportion_correct(tokens_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Level\n",
    "All lines spoken by a character in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_df = pd.read_csv('/projekte/tcl/users/keithan/projectcalderon/wp1-semantic-analysis/gender-predict-pkg/results/scenes_bert-base-spanish-wwm-cased_1e-05_32_12.csv')\n",
    "print(\"Scenes Predictions\")\n",
    "proportion_correct(scenes_df)\n",
    "\n",
    "print(\"Scenes Mean Predictions\")\n",
    "geo_mean = geometric_mean_probability(scenes_df)\n",
    "\n",
    "proportion_correct(geo_mean, 'average_prediction')\n",
    "\n",
    "print(\"Scenes Geometric Mean Predictions\")\n",
    "proportion_correct(geo_mean, 'geo_predictions')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utterances\n",
    "Each line spoken by a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_df = pd.read_csv('/projekte/tcl/users/keithan/projectcalderon/wp1-semantic-analysis/gender-predict-pkg/results/utterances_bert-base-spanish_1e-05_32_14.csv')\n",
    "\n",
    "print(\"Utterances Predictions\")\n",
    "proportion_correct(utterances_df)\n",
    "\n",
    "print(\"Utterances Mean Predictions\")\n",
    "geo_mean = geometric_mean_probability(utterances_df)\n",
    "proportion_correct(geo_mean, 'average_prediction')\n",
    "\n",
    "print(\"Utterances Geometric Mean Predictions\")\n",
    "proportion_correct(geo_mean, 'geo_predictions')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert probabilites to single values rather than touples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_probabilities(df):\n",
    "    df['probabilities'] = df['probabilities'].apply(lambda x: (convert_string_to_numbers(x))[0])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['probabilities'] < .5:        \n",
    "            df.loc[index,'probabilities'] = 1 - row['probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_probabilities(masked_tokens_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
